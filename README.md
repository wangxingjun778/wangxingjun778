## Hi there! ðŸ‘‹  I'm Xingjun Wang (wangxingjun778)

**Researcher/Engineer @ Alibaba Tongyi Lab, ModelScope Team** 
<br> `Open Source Advocate` | `LLM & Agent Researcher` | `PKU & XJTU Alumnus`

---

### ðŸš€ About Me
I am a Researcher/Engineer at **Alibaba Tongyi Lab**, where I design and implement dataset infrastructure, LLM evaluation framework, and autonomous agent system for the **ModelScope** community. 

As a core maintainer of **ModelScope SDK**, **EvalScope**, **MS-Agent**, and **FaceChain**, my works follow the "code-first, research-driven" paradigm.

I earned my **M.S.** from **Peking University (PKU)** and my **B.S.** from **Xi'an Jiaotong University (XJTU)**.

---

### ðŸ” Research Interests

* **Autonomous Agent Systems**: Developing **Long-Horizon Agents** with autonomous exploration capabilities and advancing Agentic Reinforcement Learning.
* **Unified Multimodal Models**: Architecting and optimizing **Any-to-Any** multimodal understanding and generation systems (e.g., Nexus-Gen).
* **Multimodal Reasoning**: Enhancing complex logical inference and step-by-step reasoning in cross-modal architectures.
* **Automated LLM Evaluation**: Designing scalable, reliable, and bias-aware benchmarking methodologies for next-generation foundation models.

---

### ðŸ† Selected Publications

> **[Eligen](https://arxiv.org/abs/2501.01097): Entity-level controlled image generation with regional attention** > H. Zhang, Z. Duan, **Xingjun Wang**, Y. Chen, Y. Zhang.  
> *ACM Multimedia Asia 2025* | ðŸ† **Best Paper Award** > [[Paper]](https://arxiv.org/abs/2501.01097)

> **[SWIFT](https://arxiv.org/abs/2408.05517): A Scalable lightWeight Infrastructure for Fine-Tuning** > Y. Zhao, J. Huang, J. Hu, **Xingjun Wang**, et al.  
> *AAAI 2025 (System Demo)* | ðŸ› ï¸ *Core Infrastructure for LLM Fine-tuning* | ðŸ”¥ 10k+ Stars on GitHub> [[Paper]](https://arxiv.org/abs/2408.05517) | [[Code]](https://github.com/modelscope/ms-swift)

> **[UniME](https://arxiv.org/abs/2504.17432): Breaking the Modality Barrier: Universal Embedding Learning with Multimodal LLMs** > T. Gu, K. Yang, Z. Feng, **Xingjun Wang**, et al.  
> *ACM Multimedia 2025*

> **[Hie-SQL](https://arxiv.org/abs/2203.07376): History Information Enhanced Network for Context-Dependent Text-to-SQL Semantic Parsing** > Y. Zheng, H. Wang, B. Dong, **Xingjun Wang**, C. Li.  
> *ACL 2022 (Findings)*

> **[Nexus-Gen](https://arxiv.org/abs/2504.21356): A Unified Model for Image Understanding, Generation, and Editing** > H. Zhang, Z. Duan, **Xingjun Wang**, et al.  
> *arXiv 2025* | [[ModelScope]](https://www.modelscope.cn/models/DiffSynth-Studio/Nexus-Gen)

> **[FaceChain](https://arxiv.org/abs/2308.14256): A Playground for Identity-Preserving Portrait Generation** > Y. Liu, C. Yu, L. Shang, **Xingjun Wang**, et al.  
> *arXiv 2023* | ðŸ”¥ *9.5k+ Stars on GitHub* > [[Code]](https://github.com/modelscope/facechain)

---
